{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25c6457d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "import string\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "450aae15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>headline</th>\n",
       "      <th>content</th>\n",
       "      <th>root_follower</th>\n",
       "      <th>root_following</th>\n",
       "      <th>average_follower</th>\n",
       "      <th>average_following</th>\n",
       "      <th>average_time_delay</th>\n",
       "      <th>lifetime</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Beverly Hillbillies Star Donna Douglas Dies at 81</td>\n",
       "      <td>Donna Douglas, star of hit show The Beverly Hi...</td>\n",
       "      <td>11692292</td>\n",
       "      <td>111804</td>\n",
       "      <td>110526</td>\n",
       "      <td>2223</td>\n",
       "      <td>32</td>\n",
       "      <td>611</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>just in: missing afghan soldiers found trying ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8605095</td>\n",
       "      <td>1842</td>\n",
       "      <td>27605</td>\n",
       "      <td>3468</td>\n",
       "      <td>211</td>\n",
       "      <td>36075</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           headline  \\\n",
       "0   5  Beverly Hillbillies Star Donna Douglas Dies at 81   \n",
       "1   8  just in: missing afghan soldiers found trying ...   \n",
       "\n",
       "                                             content  root_follower  \\\n",
       "0  Donna Douglas, star of hit show The Beverly Hi...       11692292   \n",
       "1                                                NaN        8605095   \n",
       "\n",
       "   root_following  average_follower  average_following  average_time_delay  \\\n",
       "0          111804            110526               2223                  32   \n",
       "1            1842             27605               3468                 211   \n",
       "\n",
       "   lifetime  label  \n",
       "0       611      1  \n",
       "1     36075      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0905551d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "STOPW = set(stopwords.words('english'))\n",
    "to_delete = [\"ll\",\"no\",\"nor\",\"aren't\",\"couldn't\",'couldn',\"didn'\",'didn',\"doesn't\",'doesn',\"don't\",'don',\"hadn't\",'hadn',\"hasn't\",'hasn',\"haven't\",'haven',\"isn't\",'isn',\"mightn't\",'mightn',\"mustn't\",'mustn',\"no\",\"not\",\"shan't\",'shan',\"shouldn't\",\"shouldn\",\"will\",\"wasn't\",'wasn',\"weren't\",'weren',\"won't\",'won',\"wouldn't\",'wouldn',\"isn't\",\"that'll\"]\n",
    "STOPW = list(STOPW)+to_delete\n",
    "\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fb909d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "29b15978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordopt(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub(\"\\\\W\",\" \",text) \n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)   \n",
    "    text = \" \".join(word for word in text.split() if not (word in STOPW or word.startswith('#') or word.startswith('@') or word.startswith('$')))\n",
    "    text = \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "    return text\n",
    "df['headline_modified'] = df['headline'].apply(wordopt)\n",
    "\n",
    "\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e39da68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(nrows=3,ncols=2)\n",
    "# sns.boxplot(x='label', y='root_follower', data=df, palette='bwr', ax = axs[0,0])\n",
    "# sns.boxplot(x='label', y='root_following', data=df, palette='bwr', ax = axs[0,1])\n",
    "# sns.boxplot(x='label', y='average_follower', data=df, palette='bwr', ax = axs[1,0])\n",
    "# sns.boxplot(x='label', y='average_following', data=df, palette='bwr', ax = axs[1,1])\n",
    "# sns.boxplot(x='label', y='average_time_delay', data=df, palette='bwr', ax = axs[2,0])\n",
    "# sns.boxplot(x='label', y='lifetime', data=df, palette='bwr', ax = axs[2,1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a676c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.ylim(0, 20000000)\n",
    "# sns.boxplot(x='label', y='root_follower', data=df, palette='bwr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "357632be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.ylim(0, 10000)\n",
    "#sns.boxplot(x='label', y='root_following', data=df, palette='bwr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa0b3f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.ylim(0, 100000)\n",
    "# sns.boxplot(x='label', y='average_follower', data=df, palette='bwr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27b63b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.ylim(0, 10000)\n",
    "# sns.boxplot(x='label', y='average_following', data=df, palette='bwr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4f3c29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.ylim(0, 3000)\n",
    "# sns.boxplot(x='label', y='average_time_delay', data=df, palette='bwr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b70dc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.ylim(0, 80000)\n",
    "# sns.boxplot(x='label', y='lifetime', data=df, palette='bwr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "9fafd612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_modified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beverly hillbilly star donna douglas dy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>missing afghan soldier found trying enter cana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>riphulkhogan heart ripping like shirt wwe miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chick fil manager allegedly banned hilarious l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>islamic tribunal using sharia law texas confir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   headline_modified\n",
       "0            beverly hillbilly star donna douglas dy\n",
       "1  missing afghan soldier found trying enter cana...\n",
       "2     riphulkhogan heart ripping like shirt wwe miss\n",
       "3  chick fil manager allegedly banned hilarious l...\n",
       "4  islamic tribunal using sharia law texas confir..."
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collumn = []\n",
    "collumn_with_headline = collumn + ['headline_modified']\n",
    "X = df[collumn_with_headline]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "0824a7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label\n",
       "0      1\n",
       "1      1"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y= df[['label']]\n",
    "y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "28e6c84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abbott</th>\n",
       "      <th>abc</th>\n",
       "      <th>abc interview</th>\n",
       "      <th>abc news</th>\n",
       "      <th>abdulfattah</th>\n",
       "      <th>abdulfattah jandali</th>\n",
       "      <th>accident</th>\n",
       "      <th>accidentally</th>\n",
       "      <th>act</th>\n",
       "      <th>actor</th>\n",
       "      <th>...</th>\n",
       "      <th>world</th>\n",
       "      <th>world largest</th>\n",
       "      <th>would</th>\n",
       "      <th>year</th>\n",
       "      <th>year old</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>zehaf</th>\n",
       "      <th>zehaf bibeau</th>\n",
       "      <th>zimmerman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abbott  abc  abc interview  abc news  abdulfattah  abdulfattah jandali  \\\n",
       "0       0    0              0         0            0                    0   \n",
       "1       0    0              0         0            0                    0   \n",
       "2       0    0              0         0            0                    0   \n",
       "3       0    0              0         0            0                    0   \n",
       "4       0    0              0         0            0                    0   \n",
       "\n",
       "   accident  accidentally  act  actor  ...  world  world largest  would  year  \\\n",
       "0         0             0    0      0  ...      0              0      0     0   \n",
       "1         0             0    0      0  ...      0              0      0     0   \n",
       "2         0             0    0      0  ...      0              0      0     0   \n",
       "3         0             0    0      0  ...      0              0      0     0   \n",
       "4         0             0    0      0  ...      0              0      0     0   \n",
       "\n",
       "   year old  york  young  zehaf  zehaf bibeau  zimmerman  \n",
       "0         0     0      0      0             0          0  \n",
       "1         0     0      0      0             0          0  \n",
       "2         0     0      0      0             0          0  \n",
       "3         0     0      0      0             0          0  \n",
       "4         0     0      0      0             0          0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(ngram_range=(1,2), max_features=1000)\n",
    "X_txt = vect.fit_transform(X['headline_modified'])\n",
    "X_txt = pd.DataFrame(X_txt.toarray(),columns=vect.get_feature_names())\n",
    "\n",
    "X_txt.index=range(0,817)\n",
    "X_final = pd.concat([X_txt,X[collumn]],axis=1)\n",
    "# X_final = X_txt\n",
    "X_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb11a53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "5e81a4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abbott</th>\n",
       "      <th>abc</th>\n",
       "      <th>abc interview</th>\n",
       "      <th>abc news</th>\n",
       "      <th>abdulfattah</th>\n",
       "      <th>abdulfattah jandali</th>\n",
       "      <th>accident</th>\n",
       "      <th>accidentally</th>\n",
       "      <th>act</th>\n",
       "      <th>actor</th>\n",
       "      <th>...</th>\n",
       "      <th>world</th>\n",
       "      <th>world largest</th>\n",
       "      <th>would</th>\n",
       "      <th>year</th>\n",
       "      <th>year old</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>zehaf</th>\n",
       "      <th>zehaf bibeau</th>\n",
       "      <th>zimmerman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     abbott  abc  abc interview  abc news  abdulfattah  abdulfattah jandali  \\\n",
       "14        0    0              0         0            0                    0   \n",
       "473       0    0              0         0            0                    0   \n",
       "46        0    0              0         0            0                    0   \n",
       "435       0    0              0         0            0                    0   \n",
       "170       0    0              0         0            0                    0   \n",
       "\n",
       "     accident  accidentally  act  actor  ...  world  world largest  would  \\\n",
       "14          0             0    0      0  ...      0              0      0   \n",
       "473         0             0    0      0  ...      0              0      0   \n",
       "46          0             0    0      0  ...      0              0      0   \n",
       "435         0             0    0      0  ...      0              0      0   \n",
       "170         0             0    0      0  ...      0              0      0   \n",
       "\n",
       "     year  year old  york  young  zehaf  zehaf bibeau  zimmerman  \n",
       "14      1         0     0      0      0             0          0  \n",
       "473     0         0     0      0      0             0          0  \n",
       "46      1         0     0      0      0             0          0  \n",
       "435     0         0     0      0      0             0          0  \n",
       "170     0         0     0      0      0             0          0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_final,y,test_size=0.3)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "5c2d542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.values\n",
    "X_test=X_test.values\n",
    "y_train=y_train.values\n",
    "y_test=y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0152159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from sklearn.metrics import make_scorer, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8a44379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('logisticregression', LogisticRegression())])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipe_logis=make_pipeline(LogisticRegression())\n",
    "# pipe_logis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b57e3664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logis_param_grid = {\n",
    "#     'logisticregression__l1_ratio':np.arange(0,1,0.05),\n",
    "#     'logisticregression__C':np.arange(0,10,0.5)\n",
    "# }\n",
    "# randomized_search_logis = RandomizedSearchCV(estimator=pipe_logis, param_distributions=logis_param_grid, n_iter=100, scoring=make_scorer(accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ffcfe35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "106e25a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sg/q8xby2yn5qj6m5cd_p6tsky80000gq/T/ipykernel_21826/4231502803.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandomized_search_logis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandomized_search_logis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "# print(randomized_search_logis.best_params_)\n",
    "# print(randomized_search_logis.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8d405414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logis_model=LogisticRegression(l1_ratio=0.15,class_weight='balanced',C=7.5)\n",
    "# # logis_model.fit(X_train,y_train)\n",
    "\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8abaaa90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4878048780487805\n"
     ]
    }
   ],
   "source": [
    "# logis_pred=logis_model.predict(X_test)\n",
    "# #cm = confusion_matrix(y_test,logis_pred)\n",
    "# print(accuracy_score(y_test,logis_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4f3a87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edb5f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae542263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67e0aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00361cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "02931dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e32072ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8617886178861789\n"
     ]
    }
   ],
   "source": [
    "rf_pred=rf.predict(X_test)\n",
    "print(accuracy_score(y_test,rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ce639b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33525b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_classifier=GradientBoostingClassifier()\n",
    "gradient_classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b34d095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5975609756097561\n"
     ]
    }
   ],
   "source": [
    "gradient_pred=gradient_classifier.predict(X_test)\n",
    "print(accuracy_score(y_test,gradient_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "faff5bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9b5f2dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GaussianNB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sg/q8xby2yn5qj6m5cd_p6tsky80000gq/T/ipykernel_21826/4237813440.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnaive_classifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnaive_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnaive_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnaive_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnaive_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GaussianNB' is not defined"
     ]
    }
   ],
   "source": [
    "naive_classifier=GaussianNB()\n",
    "naive_classifier.fit(X_train,y_train)\n",
    "naive_pred=naive_classifier.predict(X_test)\n",
    "print(accuracy_score(y_test,naive_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
